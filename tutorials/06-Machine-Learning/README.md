# üîÅ Reinforcement Learning com DQN (Deep-Q-Learning) no TurtleBot3

Este tutorial utiliza Aprendizado por Refor√ßo, uma **t√©cnica de Aprendizado de M√°quina** onde o **TurtleBot3** aprende a agir por tentativa e erro, recebendo recompensas ou puni√ß√µes com base em suas a√ß√µes, utilizando os pacotes padr√£o do ROS2.

O algoritmo usado √© o **Deep Q-Learning (DQN)**, que combina redes neurais com aprendizado por refor√ßo para ensinar o TurtleBot3 a tomar decis√µes eficazes em ambientes complexos e din√¢micos.

> **Importante:** Todos os comandos devem ser executados **dentro do container Docker**.

---

## üì¶ 1Ô∏è‚É£ Configura√ß√£o Inicial

### **Passo 1: Iniciar o Container**
Caso ainda n√£o esteja rodando:
```bash
./run.sh turtlebot3_ros2:latest
```
Caso precise abrir um novo terminal dentro do container:
```bash
docker exec -it turtlebot3_container bash
```
### **Passo 2: Definir o Modelo do TurtleBot3**
O modelo padr√£o √© **`waffle`**, mas pode ser alterado antes da execu√ß√£o:
```bash
export TURTLEBOT3_MODEL=burger  # Op√ß√µes: burger, waffle, waffle_pi
```
---

## üßæ Definir par√¢metros 

O objetivo do Agente DQN √© fazer com que o TurtleBot3 alcance o objetivo evitando os obst√°culos. Quando o TurtleBot3 se aproxima do destino, ele recebe uma recompensa positiva; quando se afasta, recebe uma recompensa negativa.

O epis√≥dio termina quando:

* o TurtleBot3 colide com um obst√°culo
* Um determinado tempo limite √© atingido.

Durante o epis√≥dio:

* O TurtleBot3 recebe uma grande recompensa positiva ao alcan√ßar o objetivo.
* Uma grande puni√ß√£o negativa caso colida com um obst√°culo.

## üì° Definir Estado

O estado representa uma observa√ß√£o do ambiente, descrevendo a situa√ß√£o atual do TurtleBot3.
Neste caso, o state_size √© 26, composto por:
* 24 valores do LDS (sensor de dist√¢ncia),
* dist√¢ncia at√© o objetivo, e
* √¢ngulo at√© o objetivo.

Por padr√£o, o LDS do TurtleBot3 tem 360 amostras.
Voc√™ pode modificar essa amostragem desta forma no terminal:
```bash
nano /turtlebot3_simulations/turtlebot3_gazebo/models/turtlebot3_waffle/model.sdf
```

Procure por: 
```bash
<sensor name="hls_lfcd_lds" type="ray">    # Find the "hls_lfcd_lds"
  <visualize>true</visualize>    # Visualization of LDS. If you don't want to see LDS, set to `false`
``` 
```bash
<scan>
  <horizontal>
    <samples>360</samples>    # The number of sample. Modify it to 24
    <resolution>1.000000</resolution>
    <min_angle>0.000000</min_angle>
    <max_angle>6.280000</max_angle>
  </horizontal>
</scan>
```
## üî¢ Descri√ß√£o dos est√°gios 
### 1. Est√°gio 1 (Sem obst√°culo)
Est√°gio 1 √© um mapa 4x4 sem obst√°culo
![alt text](images/stage1.png)

### 2. Est√°gio 2 (Obst√°culo est√°tico)
Est√°gio 2 √© um mapa 4x4 com 4 cilindros como obst√°culos est√°ticos
![alt text](images/stage2.png)

### 3. Est√°gio 3 (Obst√°culo m√≥vel)
Est√°gio 3 √© um mapa 4x4 com 4 cilindros como obst√°culos m√≥veis
![alt text](images/stage3.png)

### 4. Est√°gio 4 (Combina√ß√£o de obst√°culos)
Est√°gio 4 √© um mapa 5x5 com paredes e 2 cilindros como obst√°culos est√°ticos
![alt text](images/stage4.png)

## ‚ñ∂Ô∏è Executar o Aprendizado de M√°quina

### üó∫Ô∏è Carregar o Est√°gio no Mapa do Gazebo

Este comando carrega o ambiente de simula√ß√£o correspondente ao est√°gio desejado:
```bash
ros2 launch turtlebot3_gazebo turtlebot3_dqn_{$stage_num}.launch.py
```

### üåê Executar o N√≥ do Ambiente no Gazebo

Este n√≥ gerencia o ambiente no Gazebo. Ele reinicia a posi√ß√£o do TurtleBot3 e gera um novo objetivo sempre que um novo epis√≥dio come√ßa:
```bash
ros2 run turtlebot3_dqn dqn_gazebo {$stage_num}
```

### üß† Executar o N√≥ do Ambiente DQN

Este n√≥ calcula o estado do TurtleBot3 com base na simula√ß√£o, al√©m de determinar as recompensas, sucesso e falha em cada epis√≥dio:
```bash
ros2 run turtlebot3_dqn dqn_environment
```

### ü§ñ Executar o N√≥ do Agente DQN

Este n√≥ √© respons√°vel por treinar o TurtleBot3. Ele usa as recompensas calculadas para ajustar o comportamento do rob√¥ a cada epis√≥dio:

```bash
ros2 run turtlebot3_dqn dqn_agent {$stage_num} {$max_training_episodes}
```

### üß™ Testar o Modelo Treinado

Ap√≥s o treinamento, voc√™ pode testar o modelo treinado substituindo o agente pelo n√≥ de teste:
```bash
ros2 run turtlebot3_dqn dqn_test {$stage_num} {$load_episode}
```

## üìä Vizualizar o Gr√°fico de Aprendizado de M√°quina
### üèÜ Gr√°fico de A√ß√µes

O gr√°fico de a√ß√µes mostra a a√ß√£o atual do TurtleBot3, as recompensas obtidas e o total de recompensas durante o epis√≥dio.
```bash
ros2 run turtlebot3_dqn action_graph
```

### üìà Gr√°fico de Resultados

O gr√°fico de resultados √© um gr√°fico linear que mostra a m√©dia dos valores m√°ximos do Q-Value e a recompensa total conforme o epis√≥dio progride.
```bash
ros2 run turtlebot3_dqn result_graph
```

## üìö Refer√™ncias
- [TurtleBot3 - Machine Learning](https://emanual.robotis.com/docs/en/platform/turtlebot3/machine_learning/#machine-learning)

---